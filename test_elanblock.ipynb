{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* ELANBlock 상위 클래스 만들어서 기본 메소드 상속하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov7 in common.py\n",
    "class Conv(nn.Module):\n",
    "    # Standard convolution\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(Conv, self).__init__()\n",
    "        p=k//2\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, p, groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "    \n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dimension=1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.d = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Backbone\n",
    "class BBoneELANBlock(nn.Module):\n",
    "    def __init__(self, c1, k, depth):\n",
    "        super(BBoneELANBlock, self).__init__()\n",
    "        assert c1 % 2 == 0 and depth < 5\n",
    "        c_ = int(c1 / 2)\n",
    "        \n",
    "        self.depth = depth\n",
    "        \n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c1, c_, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c_, c_, k, 1)\n",
    "        self.cv4 = Conv(c_, c_, k, 1)\n",
    "        # depth 3\n",
    "        self.cv5 = Conv(c_, c_, k, 1)\n",
    "        self.cv6 = Conv(c_, c_, k, 1)\n",
    "        # depth 4\n",
    "        self.cv7 = Conv(c_, c_, k, 1)\n",
    "        self.cv8 = Conv(c_, c_, k, 1)\n",
    "        \n",
    "        self.act_idx = [0, 1, 3, 5, 7][:depth+1] \n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        # depth 1\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 3\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        # depth 4\n",
    "        x7 = self.cv7(x6)\n",
    "        outputs.append(x7)\n",
    "        x8 = self.cv8(x7)\n",
    "        outputs.append(x8)\n",
    "        \n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block = BBoneELANBlock(c1=128, k=3, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Head\n",
    "# there are differences about cardinality(path) and channel size\n",
    "class HEADELANBlock(nn.Module):\n",
    "    def __init__(self, c1, k, depth):\n",
    "        super(HEADELANBlock, self).__init__()\n",
    "        assert c1 % 2 == 0 and depth < 6\n",
    "        c_ = int(c1 / 2)\n",
    "        c_2 = int(c_ / 2)\n",
    "        self.depth = depth\n",
    "        \n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c1, c_, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c_, c_2, k, 1)\n",
    "        # depth 3\n",
    "        self.cv4 = Conv(c_2, c_2, k, 1)\n",
    "        # depth 4\n",
    "        self.cv5 = Conv(c_2, c_2, k, 1)\n",
    "        # depth 5\n",
    "        self.cv6 = Conv(c_2, c_2, k, 1)\n",
    "        \n",
    "        self.act_idx = [0, 1, 2, 3, 4, 5, 6][:depth+1] \n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        # depth 1\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        # depth 3\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 4\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        # depth 5\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        \n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block = HEADELANBlock(c1=128, k=3, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 64, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Backbone\n",
    "class ELANBlock(nn.Module):\n",
    "    def __init__(self, c1, k, depth):\n",
    "        super(ELANBlock, self).__init__()\n",
    "        assert c1 % 2 == 0 and depth < 5\n",
    "        c_ = int(c1 / 2)\n",
    "        c2 = int(c1 / 2 * (depth+1))\n",
    "        self.depth = depth\n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c1, c_, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c_, c_, 3, 1)\n",
    "        self.cv4 = Conv(c_, c_, 3, 1)\n",
    "        # depth 3\n",
    "        self.cv5 = Conv(c_, c_, 3, 1)\n",
    "        self.cv6 = Conv(c_, c_, 3, 1)\n",
    "        # depth 4\n",
    "        self.cv7 = Conv(c_, c_, 3, 1)\n",
    "        self.cv8 = Conv(c_, c_, 3, 1)\n",
    "        \n",
    "        self.cat = Concat(dimension=1)\n",
    "        \n",
    "        self.blocks, self.act_idx = self.set_blocks(c1, k, s, depth)\n",
    "    \n",
    "    def set_blocks(self, c1, k, s, depth):\n",
    "        c_ = int(c1 / 2)\n",
    "        layers = []\n",
    "        # depth에 따라 from 이 결정됨.\n",
    "        # depth = 3\n",
    "        act_idx = [0, 1, 3, 5, 7][:depth] \n",
    "        f = [-1, -3, -5, -6]\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                # depth 1\n",
    "                m1, m2 = Conv(c1, c_, 1, 1), Conv(c1, c_, 1, 1)\n",
    "                m1.i, m1.f = i, 0\n",
    "                m2.i, m2.f = i+1, 0\n",
    "                layers.append(m1)\n",
    "                layers.append(m2)\n",
    "                # layers.append(Conv(c1, c_, 1, 1))\n",
    "                # layers.append(Conv(c1, c_, 1, 1))\n",
    "            else:\n",
    "                # another depth\n",
    "                m3, m4 = Conv(c_, c_, k, 1), Conv(c_, c_, k, 1)\n",
    "                m3.i, m3.f = 2*i, 2*i-1\n",
    "                m4.i, m4.f = 2*i+1, 2*i\n",
    "                layers.append(m3)\n",
    "                layers.append(m4)\n",
    "                # layers.append(Conv(c_, c_, k, 1))\n",
    "                # layers.append(Conv(c_, c_, k, 1))\n",
    "                m = nn.Sequential(\n",
    "                    Conv(c_, c_, k, 1),\n",
    "                    Conv(c_, c_, k, 1)\n",
    "                )\n",
    "                \n",
    "        \n",
    "        layers.append(Concat(1))\n",
    "        return nn.Sequential(*layers), act_idx\n",
    "    \n",
    "    # def forward(self, x):\n",
    "    #     x1 = self.cv1(x)\n",
    "    #     x2 = self.cv2(x)    \n",
    "    #     # depth 2\n",
    "    #     x3 = self.cv3(x2)\n",
    "    #     x4 = self.cv4(x3)\n",
    "    #     # depth 3\n",
    "    #     x5 = self.cv5(x4)\n",
    "    #     x6 = self.cv6(x5)\n",
    "        \n",
    "    #     x = self.depth\n",
    "    #     return torch.cat([x1, x2, x4, x6], dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 3\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        # depth 4\n",
    "        x7 = self.cv7(x6)\n",
    "        outputs.append(x7)\n",
    "        x8 = self.cv8(x7)\n",
    "        outputs.append(x8)\n",
    "        \n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1) # 0, 1, 3, 5 \n",
    "        # return torch.cat([x1, x2, x4, x6], dim=1)\n",
    "    \n",
    "    def forward_blocks(self, x, depth=3):\n",
    "        self.saved = []\n",
    "        output = []\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if isinstance(block.f, int):\n",
    "                output.append(block(x))\n",
    "            \n",
    "        return self.cat(output[self.act_idx])            \n",
    "\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block = ELANBlock(c1=128, k=3, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
