{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.common import *\n",
    "from models.common import Conv, Concat, MP, SPPCSPC, RepConv\n",
    "from models.yolo import IDetect\n",
    "from utils.general import make_divisible\n",
    "from copy import deepcopy\n",
    "\n",
    "# libraries from ofa\n",
    "from ofa.imagenet_classification.elastic_nn.modules.dynamic_layers import DynamicConvLayer, DynamicConv2d, DynamicBatchNorm2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* ELANBlock 상위 클래스 만들어서 기본 메소드 상속하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov7 in common.py\n",
    "class Conv(nn.Module):\n",
    "    # Standard convolution\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(Conv, self).__init__()\n",
    "        p=k//2\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, p, groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dimension=1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.d = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, self.d)\n",
    "\n",
    "\n",
    "class DyConv(nn.Module):\n",
    "    # Dynamic Convolution for elastic channel size\n",
    "    def __init__(self, c1, c2, k=1, s=1, act=True):  # ch_in, ch_out, kernel, stride\n",
    "        super(DyConv, self).__init__()\n",
    "        self.conv = DynamicConv2d(c1, c2, k, s) # auto same padding\n",
    "        self.bn = DynamicBatchNorm2d(c2)\n",
    "        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELAN(nn.Module):\n",
    "    def __init__(self, c1, c2, k, depth):\n",
    "        super(ELAN, self).__init__()\n",
    "        assert c1 % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELANBlock(nn.Module):\n",
    "    def __init__(self, layers, depth):\n",
    "        super(ELANBlock, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.act_idx = [idx for idx in range(depth * 2) if (idx % 2 == 1 or idx == 0)] # it is only for Bbone\n",
    "        self.act_idx = [idx for idx in range(depth + 1)]\n",
    "    \n",
    "    def forward(self, x, d=None):\n",
    "        outputs = []\n",
    "        for i, m in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                outputs.append(m(x))\n",
    "            else:\n",
    "                x = m(x)\n",
    "                outputs.append(x)\n",
    "                \n",
    "        if d is not None:\n",
    "            return torch.cat([outputs[i] for i in self.act_idx[:d+1]], dim=1)\n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (1): Conv(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (2): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (3): Conv(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (4): BBoneELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv7): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv8): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (5): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (6): MP(\n",
       "    (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (7): Conv(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (8): Conv(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (9): Conv(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (10): Concat()\n",
       "  (11): BBoneELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv7): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv8): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (12): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (13): MP(\n",
       "    (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (14): Conv(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (15): Conv(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (16): Conv(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (17): Concat()\n",
       "  (18): BBoneELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv7): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv8): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (19): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (20): MP(\n",
       "    (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (21): Conv(\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (22): Conv(\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (23): Conv(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (24): Concat()\n",
       "  (25): BBoneELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv7): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv8): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (26): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (27): SPPCSPC(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "      (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv7): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (28): Conv(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (29): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (30): Conv(\n",
       "    (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (31): Concat()\n",
       "  (32): HeadELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (33): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (34): Conv(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (35): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (36): Conv(\n",
       "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (37): Concat()\n",
       "  (38): HeadELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (39): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (40): MP(\n",
       "    (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (41): Conv(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (42): Conv(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (43): Conv(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (44): Concat()\n",
       "  (45): HeadELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (46): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (47): MP(\n",
       "    (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (48): Conv(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (49): Conv(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (50): Conv(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (51): Concat()\n",
       "  (52): HeadELAN(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv3): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv4): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv5): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (cv6): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (53): DyConv(\n",
       "    (conv): DynamicConv2d(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): DynamicBatchNorm2d(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (54): RepConv(\n",
       "    (act): SiLU()\n",
       "    (rbr_dense): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (rbr_1x1): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (55): RepConv(\n",
       "    (act): SiLU()\n",
       "    (rbr_dense): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (rbr_1x1): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (56): RepConv(\n",
       "    (act): SiLU()\n",
       "    (rbr_dense): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (rbr_1x1): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (57): IDetect(\n",
       "    (m): ModuleList(\n",
       "      (0): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (ia): ModuleList(\n",
       "      (0): ImplicitA()\n",
       "      (1): ImplicitA()\n",
       "      (2): ImplicitA()\n",
       "    )\n",
       "    (im): ModuleList(\n",
       "      (0): ImplicitM()\n",
       "      (1): ImplicitM()\n",
       "      (2): ImplicitM()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_block = BBoneELAN(c1=128, c2=64, k=3, depth=4)\n",
    "depth = 3\n",
    "act_idx = b_block.act_idx[depth]\n",
    "layers = deepcopy(b_block.layers[:act_idx+1])\n",
    "block = ELANBlock(layers, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ELANBlock(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (4): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_block\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 64, 64])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Backbone\n",
    "class BBoneELAN(ELAN):\n",
    "    def __init__(self, c1, c2, k, depth):\n",
    "        super(BBoneELAN, self).__init__(c1, c2, k, depth)\n",
    "        assert c1 % 2 == 0 and depth < 5\n",
    "        c_ = int(c1 / 2)\n",
    "        self.c2 = c2\n",
    "        \n",
    "        self.depth = depth\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c2, 1, 1)\n",
    "        self.cv2 = Conv(c1, c2, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c2, c2, k, 1)\n",
    "        self.cv4 = Conv(c2, c2, k, 1)\n",
    "        # depth 3\n",
    "        self.cv5 = Conv(c2, c2, k, 1)\n",
    "        self.cv6 = Conv(c2, c2, k, 1)\n",
    "        # depth 4\n",
    "        self.cv7 = Conv(c2, c2, k, 1)\n",
    "        self.cv8 = Conv(c2, c2, k, 1)\n",
    "        \n",
    "        self.act_idx = [0, 1, 3, 5, 7][:depth+1] \n",
    "    \n",
    "        layers.append(self.cv1)\n",
    "        layers.append(self.cv2)\n",
    "        layers.append(self.cv3)\n",
    "        layers.append(self.cv4)\n",
    "        layers.append(self.cv5)\n",
    "        layers.append(self.cv6)\n",
    "        layers.append(self.cv7)\n",
    "        layers.append(self.cv8)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def set_depth(self, depth):\n",
    "        self.depth = depth\n",
    "        self.out_C = self.c2 * (depth + 1)\n",
    "    \n",
    "    def forward_once(self, x, d=None):\n",
    "        outputs = []\n",
    "        for i, m in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                outputs.append(m(x))\n",
    "            else:\n",
    "                x = m(x)\n",
    "                outputs.append(x)\n",
    "                \n",
    "        if d is not None:\n",
    "            return torch.cat([outputs[i] for i in self.act_idx[:d+1]], dim=1)\n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)\n",
    "    \n",
    "    def forward(self, x, d=None):\n",
    "        outputs = []\n",
    "        # depth 1\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 3\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        # depth 4\n",
    "        x7 = self.cv7(x6)\n",
    "        outputs.append(x7)\n",
    "        x8 = self.cv8(x7)\n",
    "        outputs.append(x8)\n",
    "        \n",
    "        if d is not None:\n",
    "            return torch.cat([outputs[i] for i in self.act_idx[:d+1]], dim=1)\n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block = BBoneELAN(c1=128, c2=64, k=3, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 320, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 192, 64, 64]),\n",
       " torch.Size([1, 128, 64, 64]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.forward_once(input).shape, block.forward_once(input, d=3).shape, block.forward_once(input, d=2).shape, block.forward_once(input, d=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 320, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 192, 64, 64]),\n",
       " torch.Size([1, 128, 64, 64]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape, block(input, d=3).shape, block(input, d=2).shape, block(input, d=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2 * (depth + 1)\n",
    "dyconv = DyConv(64*(4+1), 256, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyconv(block(input)).shape, dyconv(block(input, d=3)).shape, dyconv(block(input, d=2)).shape, dyconv(block(input, d=1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can even search the out channel size\n",
    "dyconv.conv.active_out_channel = 32\n",
    "dyconv(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Head\n",
    "# there are differences about cardinality(path) and channel size\n",
    "class HeadELAN(ELAN):\n",
    "    def __init__(self, c1, c2, k, depth):\n",
    "        super(HeadELAN, self).__init__(c1, c2, k, depth)\n",
    "        assert c1 % 2 == 0 and c2 % 2 == 0 and depth < 6\n",
    "        c_ = int(c2 / 2)\n",
    "        self.c2 = c2\n",
    "        self.depth = depth\n",
    "        \n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c2, 1, 1)\n",
    "        self.cv2 = Conv(c1, c2, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c2, c_, k, 1)\n",
    "        # depth 3\n",
    "        self.cv4 = Conv(c_, c_, k, 1)\n",
    "        # depth 4\n",
    "        self.cv5 = Conv(c_, c_, k, 1)\n",
    "        # depth 5\n",
    "        self.cv6 = Conv(c_, c_, k, 1)\n",
    "        \n",
    "        self.act_idx = [0, 1, 2, 3, 4, 5, 6][:depth+1] \n",
    "    \n",
    "    def forward(self, x, d=None):\n",
    "        outputs = []\n",
    "        # depth 1\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        # depth 3\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 4\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        # depth 5\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        \n",
    "        if d is not None:\n",
    "            return torch.cat([outputs[i] for i in self.act_idx[:d+1]], dim=1)\n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 512, 64, 64)\n",
    "block = HeadELAN(c1=512, c2=256, k=3, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1024, 64, 64]),\n",
       " torch.Size([1, 896, 64, 64]),\n",
       " torch.Size([1, 768, 64, 64]),\n",
       " torch.Size([1, 640, 64, 64]),\n",
       " torch.Size([1, 512, 64, 64]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape, block(input, d=4).shape, block(input, d=3).shape, block(input, d=2).shape, block(input, d=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2 // 2 * (depth + 3)\n",
    "dyconv = DyConv(256//2*(5+3), 256, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]),\n",
       " torch.Size([1, 256, 64, 64]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyconv(block(input)).shape, dyconv(block(input, d=3)).shape, dyconv(block(input, d=2)).shape, dyconv(block(input, d=1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can even search the out channel size\n",
    "dyconv.conv.active_out_channel = 32\n",
    "dyconv(input).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOSuperNet\n",
    "\n",
    "* parse_supernet 함수 정의\n",
    ": BBoneELAN과 HeadELAN에 대한 c2 계산 방식이 상이함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_supernet(d, ch):  # model_dict, input_channels(3)\n",
    "    print('\\n%3s%18s%3s%10s  %-40s%-30s' % ('', 'from', 'n', 'params', 'module', 'arguments'))\n",
    "    anchors, nc, gd, gw = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple']\n",
    "    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors\n",
    "    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)\n",
    "\n",
    "    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out\n",
    "    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args\n",
    "        m = eval(m) if isinstance(m, str) else m  # eval strings\n",
    "        for j, a in enumerate(args):\n",
    "            try:\n",
    "                args[j] = eval(a) if isinstance(a, str) else a  # eval strings\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        n = max(round(n * gd), 1) if n > 1 else n  # depth gain\n",
    "        if m in [nn.Conv2d, Conv, RepConv, SPPCSPC, DyConv]:\n",
    "            c1, c2 = ch[f], args[0]\n",
    "            if c2 != no:  # if not output\n",
    "                c2 = make_divisible(c2 * gw, 8)\n",
    "\n",
    "            args = [c1, c2, *args[1:]]\n",
    "            if m in [SPPCSPC]:\n",
    "                args.insert(2, n)  # number of repeats\n",
    "                n = 1\n",
    "        elif m is BBoneELAN:\n",
    "            c1, c2 = ch[f], int(args[0]*(args[-1]+1))\n",
    "            args = [c1, *args]\n",
    "        elif m is HeadELAN:\n",
    "            c1, c2 = ch[f], int((args[0]*2) + (args[0]/2 * (args[-1]-1)))\n",
    "            args = [c1, *args]\n",
    "        elif m is nn.BatchNorm2d:\n",
    "            args = [ch[f]]\n",
    "        elif m is Concat:\n",
    "            c2 = sum([ch[x] for x in f])\n",
    "        # elif m is Chuncat:\n",
    "        #     c2 = sum([ch[x] for x in f])\n",
    "        # elif m is Shortcut:\n",
    "        #     c2 = ch[f[0]]\n",
    "        # elif m is Foldcut:\n",
    "        #     c2 = ch[f] // 2\n",
    "        elif m in [IDetect]:\n",
    "            args.append([ch[x] for x in f])\n",
    "            if isinstance(args[1], int):  # number of anchors\n",
    "                args[1] = [list(range(args[1] * 2))] * len(f)\n",
    "        # elif m is ReOrg:\n",
    "        #     c2 = ch[f] * 4\n",
    "        # elif m is Contract:\n",
    "        #     c2 = ch[f] * args[0] ** 2\n",
    "        # elif m is Expand:\n",
    "        #     c2 = ch[f] // args[0] ** 2\n",
    "        else:\n",
    "            c2 = ch[f]\n",
    "        print(m)\n",
    "        m_ = nn.Sequential(*[m(*args) for _ in range(n)]) if n > 1 else m(*args)  # module\n",
    "        t = str(m)[8:-2].replace('__main__.', '')  # module type\n",
    "        np = sum([x.numel() for x in m_.parameters()])  # number params\n",
    "        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params\n",
    "        print('%3s%18s%3s%10.0f  %-40s%-30s' % (i, f, n, np, t, args))  # print\n",
    "        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist\n",
    "        layers.append(m_)\n",
    "        if i == 0:\n",
    "            ch = []\n",
    "        ch.append(c2)\n",
    "    return nn.Sequential(*layers), sorted(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_file = '../yaml/yolov7_elan_test.yml'\n",
    "with open(yaml_file) as f:\n",
    "    yaml = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "ch, nc, anchors = 3, None, None\n",
    "\n",
    "ch = yaml['ch'] = yaml.get('ch', ch)  # input channels\n",
    "if nc and nc != yaml['nc']:\n",
    "    print(f\"Overriding model.yaml nc={yaml['nc']} with nc={nc}\")\n",
    "    yaml['nc'] = nc  # override yaml value\n",
    "if anchors:\n",
    "    print(f'Overriding model.yaml anchors with anchors={anchors}')\n",
    "    yaml['anchors'] = round(anchors)  # override yaml value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "<class '__main__.Conv'>\n",
      "  0                -1  1       928  Conv                                    [3, 32, 3, 1]                 \n",
      "<class '__main__.Conv'>\n",
      "  1                -1  1     18560  Conv                                    [32, 64, 3, 2]                \n",
      "<class '__main__.Conv'>\n",
      "  2                -1  1     36992  Conv                                    [64, 64, 3, 1]                \n",
      "<class '__main__.Conv'>\n",
      "  3                -1  1     73984  Conv                                    [64, 128, 3, 2]               \n",
      "<class '__main__.BBoneELAN'>\n",
      "  4                -1  1    238592  BBoneELAN                               [128, 64, 3, 3]               \n",
      "<class '__main__.Conv'>\n",
      "  5                -1  1     66048  Conv                                    [256, 256, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      "  6                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      "  7                -1  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      "  8                -3  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      "  9                -1  1    147712  Conv                                    [128, 128, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 10          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 11                -1  1    952320  BBoneELAN                               [256, 128, 3, 3]              \n",
      "<class '__main__.Conv'>\n",
      " 12                -1  1    263168  Conv                                    [512, 512, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      " 13                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 14                -1  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 15                -3  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 16                -1  1    590336  Conv                                    [256, 256, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 17          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 18                -1  1   3805184  BBoneELAN                               [512, 256, 3, 3]              \n",
      "<class '__main__.Conv'>\n",
      " 19                -1  1   1050624  Conv                                    [1024, 1024, 1, 1]            \n",
      "<class 'models.common.MP'>\n",
      " 20                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 21                -1  1    525312  Conv                                    [1024, 512, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 22                -3  1    525312  Conv                                    [1024, 512, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 23                -1  1   2360320  Conv                                    [512, 512, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 24          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 25                -1  1   4067328  BBoneELAN                               [1024, 256, 3, 3]             \n",
      "<class '__main__.Conv'>\n",
      " 26                -1  1   1050624  Conv                                    [1024, 1024, 1, 1]            \n",
      "<class 'models.common.SPPCSPC'>\n",
      " 27                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      "<class '__main__.Conv'>\n",
      " 28                -1  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      " 29                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "<class '__main__.Conv'>\n",
      " 30                19  1    262656  Conv                                    [1024, 256, 1, 1]             \n",
      "<class '__main__.Concat'>\n",
      " 31          [-1, -2]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 32                -1  1   1001472  HeadELAN                                [512, 256, 3, 5]              \n",
      "<class '__main__.Conv'>\n",
      " 33                -1  1    262656  Conv                                    [1024, 256, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 34                -1  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      " 35                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "<class '__main__.Conv'>\n",
      " 36                12  1     65792  Conv                                    [512, 128, 1, 1]              \n",
      "<class '__main__.Concat'>\n",
      " 37          [-1, -2]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 38                -1  1    250880  HeadELAN                                [256, 128, 3, 5]              \n",
      "<class '__main__.Conv'>\n",
      " 39                -1  1     65792  Conv                                    [512, 128, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      " 40                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 41                -1  1     16640  Conv                                    [128, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 42                -3  1     16640  Conv                                    [128, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 43                -1  1    147712  Conv                                    [128, 128, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 44      [-1, -3, 33]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 45                -1  1   1001472  HeadELAN                                [512, 256, 3, 5]              \n",
      "<class '__main__.Conv'>\n",
      " 46                -1  1    262656  Conv                                    [1024, 256, 1, 1]             \n",
      "<class 'models.common.MP'>\n",
      " 47                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 48                -1  1     66048  Conv                                    [256, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 49                -3  1     66048  Conv                                    [256, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 50                -1  1    590336  Conv                                    [256, 256, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 51      [-1, -3, 27]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 52                -1  1   4001792  HeadELAN                                [1024, 512, 3, 5]             \n",
      "<class '__main__.Conv'>\n",
      " 53                -1  1   1049600  Conv                                    [2048, 512, 1, 1]             \n",
      "<class 'models.common.RepConv'>\n",
      " 54                39  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "<class 'models.common.RepConv'>\n",
      " 55                46  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "<class 'models.common.RepConv'>\n",
      " 56                53  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "<class 'models.yolo.IDetect'>\n",
      " 57      [54, 55, 56]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n"
     ]
    }
   ],
   "source": [
    "model, save = parse_supernet(deepcopy(yaml), ch=[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_file = '../yaml/yolov7_dynamicsupernet.yml'\n",
    "with open(yaml_file) as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "ch, nc, anchors = 3, None, None\n",
    "\n",
    "ch = config['ch'] = config.get('ch', ch)  # input channels\n",
    "if nc and nc != config['nc']:\n",
    "    print(f\"Overriding model.yaml nc={config['nc']} with nc={nc}\")\n",
    "    config['nc'] = nc  # override yaml value\n",
    "if anchors:\n",
    "    print(f'Overriding model.yaml anchors with anchors={anchors}')\n",
    "    config['anchors'] = round(anchors)  # override yaml value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "<class '__main__.Conv'>\n",
      "  0                -1  1       928  Conv                                    [3, 32, 3, 1]                 \n",
      "<class '__main__.Conv'>\n",
      "  1                -1  1     18560  Conv                                    [32, 64, 3, 2]                \n",
      "<class '__main__.Conv'>\n",
      "  2                -1  1     36992  Conv                                    [64, 64, 3, 1]                \n",
      "<class '__main__.Conv'>\n",
      "  3                -1  1     73984  Conv                                    [64, 128, 3, 2]               \n",
      "<class '__main__.BBoneELAN'>\n",
      "  4                -1  1    238592  BBoneELAN                               [128, 64, 3, 3]               \n",
      "<class '__main__.DyConv'>\n",
      "  5                -1  1     66048  DyConv                                  [256, 256, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      "  6                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      "  7                -1  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      "  8                -3  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      "  9                -1  1    147712  Conv                                    [128, 128, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 10          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 11                -1  1    952320  BBoneELAN                               [256, 128, 3, 3]              \n",
      "<class '__main__.DyConv'>\n",
      " 12                -1  1    263168  DyConv                                  [512, 512, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      " 13                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 14                -1  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 15                -3  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 16                -1  1    590336  Conv                                    [256, 256, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 17          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 18                -1  1   3805184  BBoneELAN                               [512, 256, 3, 3]              \n",
      "<class '__main__.DyConv'>\n",
      " 19                -1  1   1050624  DyConv                                  [1024, 1024, 1, 1]            \n",
      "<class 'models.common.MP'>\n",
      " 20                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 21                -1  1    525312  Conv                                    [1024, 512, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 22                -3  1    525312  Conv                                    [1024, 512, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 23                -1  1   2360320  Conv                                    [512, 512, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 24          [-1, -3]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.BBoneELAN'>\n",
      " 25                -1  1   4067328  BBoneELAN                               [1024, 256, 3, 3]             \n",
      "<class '__main__.DyConv'>\n",
      " 26                -1  1   1050624  DyConv                                  [1024, 1024, 1, 1]            \n",
      "<class 'models.common.SPPCSPC'>\n",
      " 27                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      "<class '__main__.Conv'>\n",
      " 28                -1  1    131584  Conv                                    [512, 256, 1, 1]              \n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      " 29                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "<class '__main__.Conv'>\n",
      " 30                19  1    262656  Conv                                    [1024, 256, 1, 1]             \n",
      "<class '__main__.Concat'>\n",
      " 31          [-1, -2]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 32                -1  1   1001472  HeadELAN                                [512, 256, 3, 5]              \n",
      "<class '__main__.DyConv'>\n",
      " 33                -1  1    262656  DyConv                                  [1024, 256, 1, 1]             \n",
      "<class '__main__.Conv'>\n",
      " 34                -1  1     33024  Conv                                    [256, 128, 1, 1]              \n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      " 35                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "<class '__main__.Conv'>\n",
      " 36                12  1     65792  Conv                                    [512, 128, 1, 1]              \n",
      "<class '__main__.Concat'>\n",
      " 37          [-1, -2]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 38                -1  1    250880  HeadELAN                                [256, 128, 3, 5]              \n",
      "<class '__main__.DyConv'>\n",
      " 39                -1  1     65792  DyConv                                  [512, 128, 1, 1]              \n",
      "<class 'models.common.MP'>\n",
      " 40                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 41                -1  1     16640  Conv                                    [128, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 42                -3  1     16640  Conv                                    [128, 128, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 43                -1  1    147712  Conv                                    [128, 128, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 44      [-1, -3, 33]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 45                -1  1   1001472  HeadELAN                                [512, 256, 3, 5]              \n",
      "<class '__main__.DyConv'>\n",
      " 46                -1  1    262656  DyConv                                  [1024, 256, 1, 1]             \n",
      "<class 'models.common.MP'>\n",
      " 47                -1  1         0  models.common.MP                        []                            \n",
      "<class '__main__.Conv'>\n",
      " 48                -1  1     66048  Conv                                    [256, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 49                -3  1     66048  Conv                                    [256, 256, 1, 1]              \n",
      "<class '__main__.Conv'>\n",
      " 50                -1  1    590336  Conv                                    [256, 256, 3, 2]              \n",
      "<class '__main__.Concat'>\n",
      " 51      [-1, -3, 27]  1         0  Concat                                  [1]                           \n",
      "<class '__main__.HeadELAN'>\n",
      " 52                -1  1   4001792  HeadELAN                                [1024, 512, 3, 5]             \n",
      "<class '__main__.DyConv'>\n",
      " 53                -1  1   1049600  DyConv                                  [2048, 512, 1, 1]             \n",
      "<class 'models.common.RepConv'>\n",
      " 54                39  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "<class 'models.common.RepConv'>\n",
      " 55                46  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "<class 'models.common.RepConv'>\n",
      " 56                53  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "<class 'models.yolo.IDetect'>\n",
      " 57      [54, 55, 56]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n"
     ]
    }
   ],
   "source": [
    "model, save = parse_supernet(deepcopy(config), ch=[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 1. Superclass인 ELAN 블록으로 관리하는 법\n",
    "yaml['depth_list']\n",
    "elan_idx = 0\n",
    "for i, m in enumerate(model):\n",
    "    if isinstance(m, ELAN):\n",
    "        print(m.depth)\n",
    "        depth = runtime_depth[elan_idx]\n",
    "        # elan_idx += 1\n",
    "        break\n",
    "    \n",
    "# 2. BBone과 Head를 나누어서 관리하는 법\n",
    "# for m in model:\n",
    "#     if isinstance(m, BBoneELAN):\n",
    "#         print(m.depth)\n",
    "#     if isinstance(m, HeadELAN):\n",
    "#         print(m.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.c2, runtime_depth[elan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BBoneELAN(\n",
       "  (cv1): Conv(\n",
       "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv2): Conv(\n",
       "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv3): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv4): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv5): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv6): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv7): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (cv8): Conv(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv(\n",
       "  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act): SiLU()\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_width_next_layer():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 1, 'Conv', [32, 3, 1]],\n",
       " [-1, 1, 'Conv', [64, 3, 2]],\n",
       " [-1, 1, 'Conv', [64, 3, 1]],\n",
       " [-1, 1, 'Conv', [128, 3, 2]],\n",
       " [-1, 1, 'BBoneELAN', [64, 3, 3]],\n",
       " [-1, 1, 'Conv', [256, 1, 1]],\n",
       " [-1, 1, 'MP', []],\n",
       " [-1, 1, 'Conv', [128, 1, 1]],\n",
       " [-3, 1, 'Conv', [128, 1, 1]],\n",
       " [-1, 1, 'Conv', [128, 3, 2]],\n",
       " [[-1, -3], 1, 'Concat', [1]],\n",
       " [-1, 1, 'BBoneELAN', [128, 3, 3]],\n",
       " [-1, 1, 'Conv', [512, 1, 1]],\n",
       " [-1, 1, 'MP', []],\n",
       " [-1, 1, 'Conv', [256, 1, 1]],\n",
       " [-3, 1, 'Conv', [256, 1, 1]],\n",
       " [-1, 1, 'Conv', [256, 3, 2]],\n",
       " [[-1, -3], 1, 'Concat', [1]],\n",
       " [-1, 1, 'BBoneELAN', [256, 3, 3]],\n",
       " [-1, 1, 'Conv', [1024, 1, 1]],\n",
       " [-1, 1, 'MP', []],\n",
       " [-1, 1, 'Conv', [512, 1, 1]],\n",
       " [-3, 1, 'Conv', [512, 1, 1]],\n",
       " [-1, 1, 'Conv', [512, 3, 2]],\n",
       " [[-1, -3], 1, 'Concat', [1]],\n",
       " [-1, 1, 'BBoneELAN', [256, 3, 3]],\n",
       " [-1, 1, 'Conv', [1024, 1, 1]]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "yaml_file = '../yaml/yolov7_supernet.yml'\n",
    "with open(yaml_file) as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    \n",
    "config['backbone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_active_subnet(d=None, **kwargs):\n",
    "        runtime_depth = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_net(preserve_weight=True):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_net_config(yaml, runtime_depth): # self\n",
    "    idx = 0\n",
    "    d = deepcopy(yaml)\n",
    "    \n",
    "    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):\n",
    "        if 'ELAN'in m:\n",
    "            args[-1] = runtime_depth[idx]\n",
    "            idx += 1\n",
    "    \n",
    "    del d['depth_list']\n",
    "            \n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_depth = [3,2,2,1,5,5,5,3]\n",
    "d = get_active_net_config(config, runtime_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 BBoneELAN [64, 3, 3]\n",
      "11 BBoneELAN [128, 3, 2]\n",
      "18 BBoneELAN [256, 3, 2]\n",
      "25 BBoneELAN [256, 3, 1]\n",
      "32 HeadELAN [256, 3, 5]\n",
      "38 HeadELAN [128, 3, 5]\n",
      "45 HeadELAN [256, 3, 5]\n",
      "52 HeadELAN [512, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):\n",
    "    if 'ELAN'in m:\n",
    "        print(i, m, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model[-1]  # Detect()\n",
    "# s = 256  # 2x min stride\n",
    "# m.stride = torch.tensor([s / x.shape[-2] for x in forward(torch.zeros(1, ch, s, s))])  # forward\n",
    "# check_anchor_order(m)\n",
    "# m.anchors /= m.stride.view(-1, 1, 1)\n",
    "# self.stride = m.stride\n",
    "# self._initialize_biases()  # only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.common import * \n",
    "from models.yolo import * \n",
    "\n",
    "def forward_once(model, x, runtime_depth, profile=False):\n",
    "    y, dt = [], []  # outputs\n",
    "    elan_idx = 0\n",
    "    for m in model:\n",
    "        if m.f != -1:  # if not from previous layer\n",
    "            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "\n",
    "        if profile:\n",
    "            c = isinstance(m, (Detect, IDetect, IAuxDetect, IBin))\n",
    "            o = thop.profile(m, inputs=(x.copy() if c else x,), verbose=False)[0] / 1E9 * 2 if thop else 0  # FLOPS\n",
    "            for _ in range(10):\n",
    "                m(x.copy() if c else x)\n",
    "            t = time_synchronized()\n",
    "            for _ in range(10):\n",
    "                m(x.copy() if c else x)\n",
    "            dt.append((time_synchronized() - t) * 100)\n",
    "            print('%10.1f%10.0f%10.1fms %-40s' % (o, m.np, dt[-1], m.type))\n",
    "\n",
    "        if isinstance(m, ELAN): # \n",
    "            depth = runtime_depth[elan_idx]\n",
    "            elan_idx += 1\n",
    "            x = m(x, d=depth)\n",
    "        else:\n",
    "            x = m(x)  # run\n",
    "        \n",
    "        y.append(x if m.i in save else None)  # save output\n",
    "\n",
    "    if profile:\n",
    "        print('%.1fms total' % sum(dt))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[[ 1.62231e-01, -1.89186e-01, -3.34552e-01,  ..., -2.17327e-01,  5.57717e-02, -2.49949e-01],\n",
       "            [ 5.83315e-01, -2.06370e-02,  2.21807e-02,  ..., -7.35443e-01, -2.08533e-01, -1.82800e-01],\n",
       "            [-3.55718e-03, -2.72500e-01, -2.94646e-01,  ..., -2.12679e-01,  7.00525e-02, -4.28083e-02],\n",
       "            ...,\n",
       "            [ 1.89134e-01, -5.20411e-01, -8.45757e-02,  ..., -7.42623e-01,  1.87639e-01, -3.75235e-01],\n",
       "            [ 2.38706e-01, -2.64785e-01,  8.81961e-02,  ..., -2.00510e-01, -7.95626e-02, -1.93366e-01],\n",
       "            [ 2.33426e-01, -5.03569e-02, -3.87518e-01,  ..., -2.86597e-01,  1.40115e-01, -2.19368e-01]],\n",
       " \n",
       "           [[-1.78110e-02,  7.72588e-02,  6.29165e-02,  ..., -5.71224e-01,  1.91088e-01,  2.82930e-02],\n",
       "            [ 4.85656e-01,  1.63607e-01, -2.14044e-01,  ..., -2.12386e-01, -4.93584e-01,  3.77903e-01],\n",
       "            [ 3.58451e-01, -5.28260e-01, -6.48423e-02,  ...,  7.46303e-02, -2.37714e-01,  1.11812e-01],\n",
       "            ...,\n",
       "            [-4.89497e-01, -7.43978e-01, -7.17234e-01,  ..., -5.94929e-01,  4.77771e-01, -3.34814e-01],\n",
       "            [-1.82517e-01, -4.72372e-01, -1.78109e-01,  ..., -8.16855e-01,  2.57586e-01,  3.77966e-01],\n",
       "            [ 8.11375e-02, -2.39691e-02, -4.79374e-01,  ..., -2.59521e-01,  6.69898e-02,  6.36083e-03]],\n",
       " \n",
       "           [[ 4.24302e-01,  8.82769e-02, -1.21442e-01,  ..., -6.19296e-01,  3.62274e-01,  3.00288e-02],\n",
       "            [ 4.99235e-01, -1.45783e-01, -1.99710e-02,  ..., -5.84618e-01, -9.03853e-01,  2.84901e-01],\n",
       "            [-1.26742e-02, -3.64372e-02, -1.61529e-01,  ..., -1.64233e-01, -2.75661e-01,  2.78996e-01],\n",
       "            ...,\n",
       "            [ 4.52226e-01,  2.95396e-01, -2.82082e-01,  ..., -9.62792e-02,  2.50171e-01, -6.42171e-02],\n",
       "            [-6.19826e-01,  1.89287e-01,  3.99934e-01,  ..., -4.37175e-01, -2.93470e-01,  1.93144e-01],\n",
       "            [-2.45695e-01, -2.16549e-01, -3.45759e-01,  ..., -2.61377e-01,  4.41934e-02, -2.79955e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 2.97045e-01,  1.08844e-01,  1.71008e-01,  ...,  1.72621e-02,  3.13534e-01, -1.40613e-01],\n",
       "            [ 6.97487e-01,  2.82020e-01, -1.05432e-01,  ...,  2.29790e-01, -1.57721e-01,  6.57014e-01],\n",
       "            [-1.35254e-01, -1.37095e-01, -1.42624e-01,  ..., -1.08276e-01,  2.31192e-01,  5.62280e-01],\n",
       "            ...,\n",
       "            [ 4.72360e-01,  4.29249e-02, -3.04795e-01,  ...,  3.53781e-02,  1.71918e-01,  4.42622e-01],\n",
       "            [ 1.17167e-01, -3.01800e-01, -9.27647e-02,  ..., -3.04891e-02,  5.21288e-01, -3.94305e-02],\n",
       "            [ 3.65907e-01, -3.43722e-02, -2.22324e-01,  ..., -1.13017e-01,  2.33905e-01, -1.30282e-01]],\n",
       " \n",
       "           [[-1.28880e-02, -2.97805e-01,  6.38104e-02,  ..., -9.62751e-02,  6.76196e-02,  4.95544e-01],\n",
       "            [ 3.22332e-01,  1.81978e-01, -1.08598e-01,  ..., -8.00650e-02,  5.23534e-02, -2.89340e-02],\n",
       "            [-1.03850e-01,  1.04607e-01, -1.92790e-01,  ..., -6.29910e-01, -2.43444e-01, -1.12854e-01],\n",
       "            ...,\n",
       "            [ 6.51959e-01,  5.74998e-01, -4.74875e-02,  ..., -1.87729e-01,  4.28705e-02, -7.79885e-01],\n",
       "            [-6.59982e-02,  2.44313e-01, -2.86135e-01,  ..., -5.22113e-01,  1.79507e-01, -4.18080e-02],\n",
       "            [ 6.72682e-01,  5.51858e-01, -2.01465e-01,  ...,  1.11610e-01,  1.22452e-01, -4.09916e-01]],\n",
       " \n",
       "           [[ 2.82116e-01, -2.58857e-02,  1.50539e-01,  ..., -3.41474e-01, -6.45688e-02,  2.63827e-01],\n",
       "            [ 1.42547e-01, -1.12367e-01,  2.46012e-01,  ...,  2.26184e-01, -2.31865e-01,  4.95282e-01],\n",
       "            [ 3.92212e-01, -1.64432e-01,  3.86920e-01,  ..., -3.26277e-01,  5.35548e-01,  7.64164e-02],\n",
       "            ...,\n",
       "            [-1.28639e-01,  1.60841e-02,  8.67160e-03,  ..., -2.66185e-01,  1.33418e-01, -2.62078e-01],\n",
       "            [-6.42508e-01, -2.73651e-01, -7.44909e-02,  ..., -1.60673e-01,  5.71741e-01, -4.67597e-02],\n",
       "            [-3.38265e-01, -1.51206e-02, -3.40408e-01,  ...,  4.79479e-02,  3.88926e-01, -7.01273e-02]]],\n",
       " \n",
       " \n",
       "          [[[-2.16813e-01, -3.87083e-01, -6.94470e-02,  ...,  3.98246e-01,  9.12977e-02,  7.11617e-01],\n",
       "            [ 2.21356e-01, -3.73905e-01,  6.17072e-02,  ...,  4.17609e-01,  1.41904e-01,  7.38819e-01],\n",
       "            [ 2.65750e-01, -2.82497e-01,  3.71215e-02,  ...,  2.51943e-01,  1.18996e-01,  2.38978e-01],\n",
       "            ...,\n",
       "            [-2.62993e-01, -5.21124e-01,  1.03753e-01,  ...,  2.69336e-01, -8.77333e-02,  4.36610e-01],\n",
       "            [-6.20149e-01, -3.71104e-01,  2.82494e-01,  ..., -1.11786e-01,  1.07226e-01,  5.79776e-01],\n",
       "            [-2.32599e-01, -5.58705e-01,  1.19088e-01,  ...,  1.18950e-01,  2.76030e-01,  5.58859e-01]],\n",
       " \n",
       "           [[ 3.72615e-02, -2.82879e-01,  1.01556e-02,  ...,  5.68309e-02,  3.58741e-01,  5.74041e-01],\n",
       "            [-6.10955e-02, -3.26598e-01,  4.36755e-01,  ...,  7.97152e-02,  2.66964e-01,  4.18331e-01],\n",
       "            [-9.30267e-03, -1.69225e-01,  4.45848e-01,  ...,  2.99072e-01,  1.64948e-01,  6.56630e-01],\n",
       "            ...,\n",
       "            [-9.94677e-01, -7.21162e-01, -1.17268e-01,  ..., -1.60989e-01,  1.75464e-02,  2.40704e-01],\n",
       "            [-4.82402e-01, -4.17404e-01,  4.43893e-01,  ...,  3.81938e-02, -8.42751e-01,  6.21226e-01],\n",
       "            [-1.41600e-01, -2.48961e-01, -5.66931e-03,  ..., -8.86409e-02, -1.49657e-02,  4.60618e-01]],\n",
       " \n",
       "           [[-1.06738e-01, -5.95370e-01,  9.46412e-02,  ...,  1.07499e-01, -1.44353e-01,  8.25894e-01],\n",
       "            [ 1.12950e-01,  3.27826e-02,  6.79006e-02,  ...,  8.08263e-02,  9.06348e-02,  3.74514e-01],\n",
       "            [-2.37247e-01,  2.12216e-01, -4.95979e-01,  ...,  8.17244e-02,  6.21218e-01,  1.41590e-01],\n",
       "            ...,\n",
       "            [ 1.19128e-01, -4.52923e-01,  5.70260e-02,  ...,  3.42053e-01, -3.28566e-01,  3.34724e-01],\n",
       "            [ 1.99709e-01, -4.41269e-01,  1.18124e-01,  ...,  7.18407e-01,  3.73835e-02,  1.22788e-01],\n",
       "            [ 5.67769e-02, -3.10949e-01, -2.04840e-01,  ...,  2.65102e-01, -2.51647e-01,  6.53826e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 4.54404e-01, -3.54108e-01,  5.74008e-01,  ..., -1.90404e-01,  1.92235e-02,  4.11360e-01],\n",
       "            [-1.25260e-01, -3.31748e-01,  2.89759e-01,  ...,  7.98282e-03, -3.52783e-01, -4.36908e-02],\n",
       "            [-3.77423e-01, -5.10898e-01,  1.96704e-01,  ..., -2.21956e-01, -2.18766e-01,  7.65988e-02],\n",
       "            ...,\n",
       "            [ 3.71676e-01,  1.30755e-01, -1.40768e-01,  ..., -1.54697e-01, -5.18165e-01,  9.05343e-01],\n",
       "            [ 7.16881e-02, -3.51903e-01,  9.88097e-01,  ...,  8.50824e-02, -1.68219e-01,  2.91024e-01],\n",
       "            [-4.89246e-01, -6.15108e-01,  9.65352e-02,  ...,  4.14918e-02,  1.38781e-01,  8.82528e-01]],\n",
       " \n",
       "           [[ 1.39074e-01, -6.73323e-01, -2.59038e-01,  ...,  1.43405e-01,  9.22986e-03,  3.40463e-01],\n",
       "            [ 1.60778e-01, -1.34315e-01, -1.11403e-01,  ...,  2.88669e-01,  6.31704e-01,  1.03586e-01],\n",
       "            [ 5.45409e-01, -3.36574e-01,  5.13067e-01,  ..., -2.07750e-01,  2.04427e-01,  1.24117e-01],\n",
       "            ...,\n",
       "            [ 3.86704e-01,  5.27888e-01,  6.47458e-01,  ...,  1.90169e-01,  1.70043e-01,  3.79570e-01],\n",
       "            [ 1.20047e-01, -3.73209e-01,  4.96415e-01,  ...,  2.74042e-01, -3.94446e-01,  2.57873e-01],\n",
       "            [-1.87496e-02, -1.01421e-01,  8.92565e-02,  ...,  6.26853e-01,  1.07502e-02,  6.66318e-01]],\n",
       " \n",
       "           [[ 1.79565e-01, -8.31963e-01,  3.44535e-01,  ..., -5.03939e-02,  3.15769e-01,  6.28430e-01],\n",
       "            [ 1.52612e-01, -6.01220e-01, -7.81585e-02,  ...,  2.44624e-01, -1.57730e-01,  7.15186e-01],\n",
       "            [ 1.07603e-01, -3.53322e-01, -3.50984e-02,  ...,  1.31842e-01,  7.52422e-03,  4.68683e-01],\n",
       "            ...,\n",
       "            [ 2.74287e-01, -1.01631e-01,  2.06038e-01,  ..., -1.36112e-02, -2.18136e-01,  3.61595e-01],\n",
       "            [ 1.42748e-01, -1.95247e-02,  3.74417e-01,  ..., -8.70585e-02, -1.03055e-01,  2.15102e-01],\n",
       "            [ 9.82695e-02, -5.69351e-01, -4.97441e-01,  ...,  3.33432e-01,  1.87641e-01,  1.78858e-01]]],\n",
       " \n",
       " \n",
       "          [[[ 5.72009e-03, -3.41525e-02,  1.19266e-01,  ..., -2.45283e-01,  1.29171e-01, -1.32705e-01],\n",
       "            [-2.83383e-01, -8.37349e-02, -5.87670e-02,  ..., -3.81644e-01,  3.60670e-01, -7.26235e-02],\n",
       "            [-2.92186e-01, -2.56632e-01, -2.41439e-01,  ..., -6.86708e-02,  3.77159e-01, -2.34964e-01],\n",
       "            ...,\n",
       "            [-1.24697e-01, -2.61673e-01,  4.08098e-01,  ..., -7.00337e-01,  2.80491e-01,  5.67972e-01],\n",
       "            [-2.14796e-01, -4.08924e-01, -1.38331e-01,  ..., -2.53542e-01,  2.15366e-01, -1.09218e-01],\n",
       "            [-3.85597e-02, -1.69217e-01,  2.06973e-01,  ..., -1.37039e-01,  1.03493e-01,  3.70488e-03]],\n",
       " \n",
       "           [[ 3.74872e-01,  8.25766e-02,  4.05373e-01,  ..., -3.17332e-03, -2.76028e-01, -1.41126e-01],\n",
       "            [ 2.69559e-01,  1.74357e-01,  1.24788e-02,  ...,  3.74009e-01, -2.39440e-01, -7.19750e-01],\n",
       "            [ 2.84157e-01,  5.64938e-01,  7.66265e-02,  ...,  1.15558e-03,  8.78431e-02,  3.26870e-01],\n",
       "            ...,\n",
       "            [-9.38186e-02,  2.06487e-01, -3.46531e-01,  ..., -5.61477e-02, -5.74845e-01,  2.30744e-01],\n",
       "            [-4.49298e-01, -3.65036e-01,  6.03708e-02,  ..., -4.02184e-01,  2.85068e-01,  1.51490e-01],\n",
       "            [-1.08534e-01,  1.35726e-01,  5.56030e-01,  ..., -3.29665e-01, -3.87371e-01,  1.41684e-01]],\n",
       " \n",
       "           [[ 5.89539e-01, -1.07972e-01,  3.08520e-01,  ..., -3.72308e-01, -8.81395e-02, -1.48918e-01],\n",
       "            [ 2.30666e-01, -8.31499e-02,  1.76766e-01,  ...,  4.43144e-01, -6.87508e-01, -5.11849e-01],\n",
       "            [-3.10353e-01,  1.68621e-01, -1.96942e-01,  ...,  2.82557e-01, -4.64130e-01, -3.91136e-01],\n",
       "            ...,\n",
       "            [ 3.72344e-01,  6.38747e-01,  4.46535e-01,  ..., -1.95872e-01, -7.29469e-01, -7.96614e-02],\n",
       "            [ 5.03755e-01, -2.33108e-01,  2.63184e-01,  ..., -3.12923e-01, -2.95793e-01, -3.19915e-01],\n",
       "            [-2.13046e-01, -5.91735e-02,  4.41480e-01,  ..., -6.46711e-01, -2.86661e-01,  1.68128e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 5.98795e-01, -1.00044e-01,  1.54070e-01,  ..., -2.42932e-01,  2.53280e-01,  4.09958e-01],\n",
       "            [ 3.69208e-01,  9.71626e-03,  1.92768e-01,  ..., -8.71020e-01, -9.82112e-02,  8.03773e-01],\n",
       "            [ 8.07893e-01,  2.68659e-01,  6.83577e-01,  ..., -2.87971e-01, -2.16442e-01,  1.29898e+00],\n",
       "            ...,\n",
       "            [ 6.76145e-02,  3.38262e-02, -3.21853e-01,  ..., -4.99004e-01, -5.53906e-01,  4.12931e-01],\n",
       "            [ 2.46534e-01, -3.20751e-01,  7.50424e-02,  ..., -9.37147e-01,  1.94544e-01,  7.89827e-04],\n",
       "            [-1.63510e-01,  2.29447e-01,  7.69998e-02,  ..., -3.80591e-01,  2.30776e-01,  5.93719e-01]],\n",
       " \n",
       "           [[ 6.29528e-01,  2.11936e-01,  1.08211e-01,  ..., -5.68641e-01, -4.73693e-01,  4.84234e-01],\n",
       "            [ 5.71354e-02, -6.74828e-02, -7.09832e-02,  ..., -4.87536e-01, -6.43091e-01,  2.78785e-01],\n",
       "            [ 3.45376e-01,  6.42839e-01, -1.05417e+00,  ..., -7.92634e-01, -1.32024e-01,  7.59549e-01],\n",
       "            ...,\n",
       "            [ 4.53355e-01, -2.54217e-02,  6.68627e-02,  ..., -1.95417e-01, -2.51575e-01, -8.17319e-02],\n",
       "            [ 2.85477e-01, -2.61243e-01, -2.23099e-01,  ...,  8.02512e-02, -3.02698e-01,  2.25595e-01],\n",
       "            [ 2.50536e-01, -2.00390e-01,  7.68889e-02,  ..., -5.81131e-01,  3.73754e-02,  6.87357e-01]],\n",
       " \n",
       "           [[ 5.04985e-01,  1.04220e-01, -2.41309e-01,  ..., -3.53325e-01, -1.77686e-01,  6.97204e-02],\n",
       "            [ 1.76913e-01,  2.52493e-01,  2.24078e-01,  ..., -6.24698e-01, -3.84137e-01,  5.15318e-01],\n",
       "            [-1.83342e-01, -6.25356e-02,  2.66296e-01,  ..., -5.68765e-01, -1.89245e-01,  5.25254e-01],\n",
       "            ...,\n",
       "            [ 2.71176e-01, -4.51686e-01,  8.09462e-02,  ...,  1.60939e-02, -2.75000e-01,  2.05139e-01],\n",
       "            [ 4.85371e-01, -4.00832e-01, -2.42359e-02,  ..., -2.03384e-01,  1.78337e-02, -1.64504e-01],\n",
       "            [-1.38450e-01, -3.86087e-01, -1.99743e-02,  ..., -1.29479e-01,  2.65688e-01,  1.36498e-01]]]]], grad_fn=<CloneBackward0>),\n",
       " tensor([[[[[-1.47113e-01,  3.65554e-02, -1.44383e-01,  ...,  1.60272e-01,  4.21710e-01, -3.70413e-01],\n",
       "            [ 2.07368e-02,  6.91342e-02, -3.45650e-01,  ...,  2.16395e-01,  4.55848e-01, -5.21559e-02],\n",
       "            [ 1.31053e-01,  3.63367e-01, -1.82573e-01,  ...,  2.85750e-01,  4.24454e-01, -9.55110e-02],\n",
       "            ...,\n",
       "            [-7.75647e-01, -3.76092e-01, -2.33206e-02,  ...,  1.95319e-01,  1.24797e-01, -1.88614e-01],\n",
       "            [-1.74777e-01, -3.49555e-01,  2.62403e-01,  ...,  1.19855e-01,  1.65283e-01, -1.36617e-01],\n",
       "            [-3.98817e-01, -1.93466e-01, -1.56559e-01,  ...,  3.56454e-01,  4.70631e-02,  2.14537e-01]],\n",
       " \n",
       "           [[ 8.67132e-02, -1.80311e-01, -3.04030e-01,  ...,  3.41875e-02,  1.32251e-01,  9.01378e-02],\n",
       "            [ 2.63892e-01, -2.65365e-01, -8.14268e-02,  ...,  6.84128e-01, -3.39981e-01,  3.99754e-01],\n",
       "            [-4.75728e-01,  1.40137e-01, -1.91775e-01,  ...,  4.53799e-01, -6.49169e-02, -2.26945e-01],\n",
       "            ...,\n",
       "            [ 7.64632e-02, -8.01259e-02,  9.71885e-02,  ..., -2.14931e-01, -1.04761e-01, -4.42732e-01],\n",
       "            [-4.01139e-01, -3.87322e-01, -4.08224e-01,  ...,  3.54023e-01, -5.56098e-01,  7.43977e-02],\n",
       "            [-3.96772e-01, -3.09113e-01, -1.88417e-02,  ...,  2.68364e-01,  3.91730e-01,  3.12088e-01]],\n",
       " \n",
       "           [[ 4.27223e-01,  3.67959e-01,  2.21655e-01,  ...,  2.96562e-01, -2.56103e-02, -1.99202e-01],\n",
       "            [-6.23632e-01,  2.02107e-02,  7.77845e-01,  ..., -2.49477e-01,  3.77645e-01,  2.52328e-01],\n",
       "            [-3.21611e-01,  5.12147e-01,  2.34103e-01,  ...,  2.80189e-01,  1.45511e-01,  5.68377e-02],\n",
       "            ...,\n",
       "            [-1.51933e-01, -7.28587e-01,  9.13692e-01,  ...,  3.80397e-01, -1.34699e-01, -1.72862e-01],\n",
       "            [-5.22424e-01, -7.74497e-01,  8.03274e-02,  ...,  4.45713e-01, -4.20749e-01, -1.05849e+00],\n",
       "            [ 2.32359e-02, -9.46581e-01, -3.69900e-01,  ..., -2.88046e-01,  3.40272e-01,  2.04702e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-5.11621e-01, -3.32374e-01, -1.53166e-01,  ...,  2.93126e-01,  2.12089e-01, -6.13267e-02],\n",
       "            [ 9.74725e-02, -4.50917e-01, -7.04689e-01,  ...,  1.67483e-01, -1.21422e-01, -1.94061e-01],\n",
       "            [ 1.22623e-01,  4.83788e-01, -7.88736e-01,  ...,  2.83125e-01,  5.66135e-01, -3.28301e-01],\n",
       "            ...,\n",
       "            [ 9.94660e-02,  3.06725e-01, -9.53092e-01,  ...,  4.40268e-01, -2.58866e-01, -5.06945e-01],\n",
       "            [ 2.03113e-01,  3.78325e-01,  3.21807e-01,  ..., -2.73705e-01, -8.19849e-01,  6.55845e-01],\n",
       "            [-6.09223e-01, -4.95540e-01, -3.41984e-01,  ...,  4.89811e-01, -6.08993e-02,  4.35738e-01]],\n",
       " \n",
       "           [[-1.79220e-01, -5.52161e-01, -5.89531e-01,  ..., -3.04557e-01,  1.36051e-01, -4.43176e-02],\n",
       "            [-4.71267e-02, -5.73274e-01,  2.76318e-02,  ...,  7.17276e-01,  3.93231e-01, -4.14251e-02],\n",
       "            [ 4.16475e-01, -1.20332e+00, -5.08141e-01,  ..., -3.02571e-01,  2.48150e-01,  7.94441e-02],\n",
       "            ...,\n",
       "            [ 2.18427e-01,  7.14765e-03, -4.91254e-01,  ...,  2.86740e-02, -7.48768e-01, -2.91647e-01],\n",
       "            [-2.71194e-01,  3.38250e-02,  9.39824e-02,  ..., -9.48897e-02, -2.17590e-01, -5.49843e-01],\n",
       "            [-3.49295e-01, -2.53561e-01, -1.80421e-01,  ...,  2.15813e-01,  2.47548e-01, -5.92667e-01]],\n",
       " \n",
       "           [[ 2.85983e-01, -8.05695e-02, -4.24923e-01,  ..., -3.13929e-02,  1.35453e-01,  4.12304e-01],\n",
       "            [-1.29822e-01, -1.76612e-01, -3.90364e-01,  ..., -6.30212e-02,  7.19697e-01,  2.00591e-01],\n",
       "            [ 1.66806e-02, -2.89699e-01, -9.22376e-02,  ...,  5.55451e-02,  9.26725e-02, -8.17151e-02],\n",
       "            ...,\n",
       "            [-1.16977e-01, -2.98563e-01, -2.12583e-01,  ...,  1.79809e-01,  1.61518e-01, -1.04118e-01],\n",
       "            [-4.68828e-02, -5.80644e-01, -1.20465e-01,  ..., -1.94501e-01, -1.80343e-01, -4.66950e-01],\n",
       "            [-4.04990e-01,  8.68804e-02, -1.80615e-02,  ...,  3.20582e-01,  9.22786e-03,  2.94531e-01]]],\n",
       " \n",
       " \n",
       "          [[[-8.59269e-03,  1.53720e-01, -2.29779e-01,  ...,  3.69648e-01,  2.32826e-01, -3.26605e-02],\n",
       "            [-7.06269e-02, -1.47577e-01, -1.53789e-02,  ...,  1.88315e-01,  5.37673e-02, -1.36306e-01],\n",
       "            [ 1.08508e-01, -3.00742e-01, -3.10652e-01,  ..., -6.02342e-02,  5.60898e-02,  1.99898e-01],\n",
       "            ...,\n",
       "            [ 2.58262e-02, -5.16596e-01, -2.80766e-01,  ...,  2.64041e-01,  5.86571e-02, -2.23357e-01],\n",
       "            [ 1.80250e-01,  2.58127e-02, -5.15413e-01,  ...,  1.79200e-01, -3.92334e-01, -2.59534e-01],\n",
       "            [-9.38984e-02,  1.22245e-01, -9.36886e-02,  ..., -2.36223e-01, -1.96870e-01, -1.25198e-01]],\n",
       " \n",
       "           [[-3.02634e-01,  1.40964e-01, -1.93119e-01,  ...,  5.69819e-02,  3.18121e-01,  1.85129e-01],\n",
       "            [ 1.05510e-01,  3.43126e-01,  1.98457e-01,  ...,  6.42655e-02,  3.93449e-01, -5.79586e-01],\n",
       "            [ 3.90654e-01,  6.34894e-03,  3.48623e-01,  ..., -4.24092e-01, -1.58123e-01,  2.90696e-01],\n",
       "            ...,\n",
       "            [-4.84368e-02, -1.78874e-02,  1.39451e-01,  ..., -4.02757e-01,  3.77119e-01,  9.53978e-02],\n",
       "            [ 1.02713e-01, -4.27401e-02,  1.51978e-01,  ..., -4.26313e-01,  2.76765e-01,  1.30210e-01],\n",
       "            [ 3.94429e-01,  4.39309e-01,  2.33597e-01,  ..., -2.28277e-01, -1.58591e-01, -3.42073e-01]],\n",
       " \n",
       "           [[ 2.65318e-01,  1.27213e-01, -5.22474e-01,  ...,  1.92110e-01, -3.14552e-01, -3.65086e-02],\n",
       "            [-5.42295e-01,  4.22921e-01, -4.83573e-02,  ...,  5.44298e-02, -3.00181e-01, -1.12194e-01],\n",
       "            [-7.03584e-02,  2.41598e-01, -2.12356e-02,  ..., -2.92246e-02,  1.92793e-02, -4.82181e-01],\n",
       "            ...,\n",
       "            [ 5.68617e-01,  1.40712e-01, -6.70102e-02,  ...,  1.75200e-01, -7.35493e-01,  3.25082e-01],\n",
       "            [-2.19296e-01,  1.50461e-01, -1.07237e-01,  ..., -5.57984e-01, -6.93159e-02, -8.37874e-02],\n",
       "            [ 2.92542e-01,  1.65594e-01, -3.82518e-01,  ...,  4.04675e-02, -2.71186e-01,  1.12739e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-9.54935e-02,  1.51314e-01, -4.18850e-01,  ...,  3.18458e-01, -1.02127e-01,  2.73712e-01],\n",
       "            [-4.85802e-01,  3.87376e-01,  4.71377e-01,  ...,  2.68573e-01, -3.51563e-01,  2.52755e-01],\n",
       "            [ 5.71452e-01, -4.61977e-01,  3.53995e-01,  ..., -5.09373e-01, -3.78110e-01, -3.58487e-01],\n",
       "            ...,\n",
       "            [ 1.25007e-01, -7.11351e-01, -7.75677e-01,  ..., -2.15950e-02, -6.00260e-02, -3.11877e-02],\n",
       "            [ 4.03116e-01, -1.33779e-01,  2.92910e-01,  ..., -2.94579e-01, -3.90981e-01, -6.63521e-01],\n",
       "            [ 8.59551e-02,  7.06148e-02, -1.41021e-01,  ...,  2.24839e-01, -3.02740e-01,  2.01570e-01]],\n",
       " \n",
       "           [[ 5.49948e-02, -1.88982e-01,  1.25210e-01,  ..., -8.67750e-02, -3.68485e-01, -3.38321e-01],\n",
       "            [ 6.20576e-01,  7.89221e-02,  5.04849e-01,  ..., -1.06075e-01, -1.53022e+00,  5.18106e-01],\n",
       "            [ 4.24030e-01, -1.15483e-01, -9.70685e-01,  ...,  1.34583e-01, -3.97139e-01,  9.11952e-01],\n",
       "            ...,\n",
       "            [ 1.75495e-01,  6.80728e-02,  3.48870e-01,  ..., -6.46337e-01,  4.51325e-01, -2.46881e-01],\n",
       "            [ 1.46440e-01,  6.81925e-01, -1.91868e-01,  ..., -4.15022e-01, -2.95699e-01, -1.75057e-01],\n",
       "            [-4.51591e-02,  1.88950e-01, -1.42339e-02,  ..., -1.33592e-01,  1.41132e-01,  1.36990e-01]],\n",
       " \n",
       "           [[ 1.38613e-01, -6.64728e-02, -2.09235e-01,  ...,  1.43459e-01, -2.30153e-01,  2.01594e-01],\n",
       "            [-3.12640e-01,  1.41834e-01,  7.47992e-02,  ..., -2.10311e-01, -9.92582e-02,  1.73660e-01],\n",
       "            [ 1.65443e-02, -4.97010e-01, -4.51200e-01,  ..., -1.38764e-01, -2.20963e-01,  2.53927e-01],\n",
       "            ...,\n",
       "            [ 1.16734e-01,  3.98456e-01, -2.93714e-01,  ..., -5.75903e-02,  2.48102e-01,  2.05519e-01],\n",
       "            [ 2.80593e-01, -1.38012e-01,  3.65441e-01,  ...,  3.52502e-01,  2.13094e-01,  1.11046e-01],\n",
       "            [ 1.64236e-01, -1.95554e-01, -6.89139e-03,  ..., -2.30178e-01, -2.19852e-01,  1.26505e-01]]],\n",
       " \n",
       " \n",
       "          [[[ 2.00183e-01,  4.25018e-01,  5.08388e-02,  ...,  1.92507e-02,  3.76425e-02, -3.05402e-01],\n",
       "            [ 8.92260e-02,  4.81148e-02,  6.76791e-02,  ..., -2.45019e-01,  4.96183e-01, -5.81091e-01],\n",
       "            [ 1.56975e-01,  2.90699e-01,  7.87228e-02,  ...,  3.64180e-01,  5.19325e-01, -2.57816e-01],\n",
       "            ...,\n",
       "            [-1.61039e-02,  4.77040e-01, -2.89310e-01,  ...,  6.77230e-02,  1.42596e-01,  3.81606e-02],\n",
       "            [-3.04564e-02,  5.68282e-02, -5.55674e-02,  ...,  3.56331e-02,  8.12115e-02,  1.86353e-01],\n",
       "            [-6.93170e-02,  3.29152e-01, -1.28878e-01,  ..., -2.32606e-01,  1.47293e-01,  6.42037e-02]],\n",
       " \n",
       "           [[-1.13749e-01,  2.07999e-01,  2.30837e-01,  ..., -2.05843e-01,  2.14865e-01,  1.02006e-02],\n",
       "            [-8.27362e-03, -1.89990e-01, -3.31453e-01,  ..., -1.67931e-01, -1.78954e-01, -8.00158e-02],\n",
       "            [ 5.51793e-01,  4.40042e-01,  2.48314e-01,  ...,  1.24630e-01,  4.04715e-01, -5.72075e-01],\n",
       "            ...,\n",
       "            [-4.34124e-03,  4.82262e-02, -2.47069e-01,  ...,  8.47175e-05, -6.47868e-01, -1.38240e-01],\n",
       "            [ 5.42238e-02,  4.68539e-02,  3.03330e-01,  ...,  1.86154e-01, -2.04797e-01, -5.24849e-01],\n",
       "            [-1.76812e-01, -4.82041e-02, -5.90210e-02,  ...,  3.67882e-02,  3.28185e-01,  2.16777e-01]],\n",
       " \n",
       "           [[-2.12967e-02, -9.78145e-02,  1.85673e-01,  ..., -1.22705e-01,  2.53143e-01, -3.65196e-02],\n",
       "            [-2.65169e-01,  2.54621e-01,  3.53230e-01,  ..., -2.29052e-01, -4.13117e-03,  1.20692e-01],\n",
       "            [ 2.18020e-01,  1.34320e-01, -4.01962e-02,  ...,  1.31555e-01,  1.96532e-01,  9.67238e-02],\n",
       "            ...,\n",
       "            [ 2.77715e-01, -2.02074e-01,  2.33903e-01,  ..., -5.29289e-01, -5.13534e-01, -9.30993e-01],\n",
       "            [-1.14865e-01, -4.61990e-01,  1.04842e+00,  ...,  5.52435e-01, -3.56679e-01, -7.22390e-01],\n",
       "            [-5.13318e-01, -1.27639e-01, -1.53449e-01,  ...,  2.57749e-01, -1.50488e-01, -1.91805e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-7.30105e-03,  2.41855e-01,  9.99884e-02,  ...,  4.54730e-01, -3.34140e-01,  8.51550e-02],\n",
       "            [-2.11844e-01,  1.88550e-01, -6.73925e-01,  ..., -2.32324e-01, -7.22165e-01,  4.61546e-01],\n",
       "            [-4.27428e-01,  3.40560e-01, -9.25788e-02,  ...,  2.27982e-01, -1.90024e-01, -8.56063e-01],\n",
       "            ...,\n",
       "            [-3.30255e-01, -6.60272e-03,  6.42217e-02,  ..., -7.35943e-01,  3.26941e-01, -3.61065e-01],\n",
       "            [ 1.76370e-01,  3.29357e-01, -4.72558e-01,  ..., -1.38072e-01,  2.47652e-01,  4.79278e-02],\n",
       "            [ 5.25022e-02, -2.97718e-02,  3.44725e-01,  ..., -2.62188e-01,  3.39129e-01, -4.52529e-01]],\n",
       " \n",
       "           [[ 4.03626e-01, -1.53003e-01,  1.80837e-01,  ..., -1.74496e-01,  2.97308e-01, -1.81159e-01],\n",
       "            [-1.36596e-01, -3.94091e-02,  2.20978e-01,  ..., -8.46212e-01,  5.57550e-01, -4.45288e-01],\n",
       "            [ 1.97910e-01,  3.16456e-01, -8.25020e-02,  ..., -4.74493e-01,  7.62442e-02, -4.71400e-01],\n",
       "            ...,\n",
       "            [-2.07222e-02, -7.08835e-01, -4.26374e-01,  ..., -2.62179e-02,  5.12904e-01, -2.63675e-01],\n",
       "            [-5.47231e-01, -9.55966e-02,  5.65270e-02,  ...,  3.88276e-01, -2.94042e-02, -4.14734e-01],\n",
       "            [-3.58647e-01, -5.45571e-02, -1.55830e-01,  ...,  1.78669e-01, -2.49680e-01, -1.85401e-01]],\n",
       " \n",
       "           [[ 2.01590e-01, -1.63191e-01,  9.76833e-02,  ..., -2.06689e-01,  1.77953e-01, -3.67324e-01],\n",
       "            [-8.77158e-02, -9.30398e-02, -7.84962e-03,  ..., -1.22229e-01,  2.49677e-01, -3.54523e-01],\n",
       "            [ 4.89297e-01,  3.48935e-01,  2.24104e-02,  ...,  1.03468e-01, -4.17882e-01, -2.89438e-01],\n",
       "            ...,\n",
       "            [-1.70872e-01, -3.93130e-03, -7.15146e-02,  ...,  1.38425e-01, -3.45930e-01, -3.12041e-01],\n",
       "            [-6.66180e-01,  6.74444e-02, -5.09861e-01,  ..., -2.51483e-02, -3.09376e-01, -3.18455e-01],\n",
       "            [ 2.02966e-01, -1.11203e-01, -7.39749e-02,  ..., -5.60050e-02,  3.36982e-01, -3.94996e-01]]]]], grad_fn=<CloneBackward0>),\n",
       " tensor([[[[[-4.60158e-02,  1.93776e-01, -1.77490e-01,  ...,  2.46321e-01, -8.75282e-02, -2.88282e-01],\n",
       "            [ 7.68842e-02,  3.51245e-01,  1.55827e-01,  ...,  3.08514e-01, -1.44478e-01, -5.31031e-01],\n",
       "            [-5.65104e-01,  2.05094e-01, -3.81344e-01,  ...,  5.12676e-01, -3.33792e-01, -3.73954e-01],\n",
       "            ...,\n",
       "            [-1.16609e-01, -3.39627e-01, -5.88378e-01,  ...,  7.50530e-01, -2.29533e-01, -4.20001e-01],\n",
       "            [-8.10409e-02, -1.57426e-02,  1.51047e-01,  ..., -1.45875e-01, -5.29391e-01,  2.46813e-02],\n",
       "            [ 2.20032e-01,  6.65628e-02,  1.55468e-01,  ...,  3.25056e-01, -4.30324e-01, -8.56704e-01]],\n",
       " \n",
       "           [[-7.37170e-01, -6.89872e-01, -1.48350e-01,  ..., -2.21294e-01,  4.28498e-02, -1.36382e-01],\n",
       "            [-1.27863e-01, -5.20361e-01,  1.69919e-01,  ...,  4.51861e-01, -2.51122e-01,  4.16633e-01],\n",
       "            [ 5.48154e-01, -1.72896e-01, -8.65652e-01,  ..., -1.86001e-02,  3.49914e-01,  4.69682e-01],\n",
       "            ...,\n",
       "            [ 7.68804e-01, -2.51926e-01, -1.58728e-01,  ..., -1.34274e-01, -1.64713e-01, -1.27207e-01],\n",
       "            [-4.69120e-01,  8.48123e-02, -7.59305e-01,  ..., -2.90301e-01, -6.85571e-01, -1.71239e-01],\n",
       "            [ 9.78081e-02, -3.00568e-01, -2.92678e-01,  ...,  2.61524e-01, -4.46074e-01,  5.64951e-02]],\n",
       " \n",
       "           [[ 2.68554e-01,  3.11648e-01, -3.67368e-01,  ..., -2.20967e-01,  9.51494e-02, -3.43112e-01],\n",
       "            [ 8.86809e-02, -6.76688e-02,  1.47174e-01,  ..., -1.72846e-01, -3.16383e-01,  5.13972e-02],\n",
       "            [ 6.40339e-02,  4.90357e-01, -1.64704e-01,  ..., -1.09633e+00, -7.58701e-01, -1.20100e+00],\n",
       "            ...,\n",
       "            [ 1.79978e-01, -9.40280e-02, -1.68517e-02,  ..., -2.27900e+00, -1.08448e+00, -5.49391e-01],\n",
       "            [ 1.46304e-02,  6.12732e-01, -2.92196e-01,  ..., -5.68747e-01, -6.65674e-02,  4.64066e-01],\n",
       "            [ 9.42456e-01,  3.21793e-01, -5.18040e-01,  ...,  1.26164e-01, -2.36508e-01,  6.67288e-03]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 1.70471e-01,  5.78836e-01, -9.44794e-02,  ...,  4.98811e-01,  5.36986e-01,  1.05926e-01],\n",
       "            [ 8.40458e-02,  3.21387e-02, -1.49909e-01,  ..., -3.08855e-01, -8.86653e-01, -3.01226e-01],\n",
       "            [ 4.22210e-01, -6.53919e-01, -3.08599e-01,  ..., -2.98945e-01, -9.48806e-01, -4.28356e-02],\n",
       "            ...,\n",
       "            [-1.25646e-01, -5.53610e-01, -1.92379e-01,  ..., -2.19715e-01, -1.15511e+00, -2.13409e-01],\n",
       "            [ 9.78703e-01,  6.00071e-01, -5.29505e-01,  ..., -4.25476e-01, -1.87172e-01, -3.78496e-01],\n",
       "            [ 4.91256e-01, -1.01089e-02,  2.99439e-01,  ..., -9.45546e-01, -1.02782e+00,  4.88666e-02]],\n",
       " \n",
       "           [[ 2.68510e-01,  1.71389e-02,  1.89939e-01,  ...,  3.60874e-01,  1.43178e-01, -5.43377e-01],\n",
       "            [ 1.21502e+00,  4.51790e-01,  4.08465e-01,  ...,  1.31191e-02, -1.22720e+00, -1.81640e-01],\n",
       "            [ 3.38447e-01,  5.25598e-02,  2.38475e-02,  ..., -6.20863e-01, -5.50870e-01, -6.67941e-01],\n",
       "            ...,\n",
       "            [-2.34806e-01,  1.67854e-01,  2.63893e-01,  ..., -2.18019e-01, -2.16248e-01, -2.72250e-01],\n",
       "            [-1.34018e-01,  4.28833e-01,  1.43397e-01,  ..., -2.23062e-01,  9.26258e-02, -5.50811e-02],\n",
       "            [ 4.43492e-02,  2.18155e-01, -2.26359e-01,  ...,  9.00442e-02, -2.00143e-01,  5.52842e-01]],\n",
       " \n",
       "           [[-3.57212e-01, -9.05861e-03, -2.86737e-01,  ..., -4.62987e-02,  3.25685e-01, -4.92605e-01],\n",
       "            [-4.02452e-01,  5.36942e-01, -3.11827e-01,  ...,  7.21394e-01,  2.31425e-01,  3.08752e-01],\n",
       "            [-1.22393e-01,  2.89033e-01, -3.96319e-02,  ...,  3.10009e-01,  1.84625e-01, -5.61119e-01],\n",
       "            ...,\n",
       "            [ 3.18701e-01,  5.34545e-02,  7.30781e-01,  ...,  1.54924e-01, -2.55996e-01, -3.73242e-01],\n",
       "            [-1.51284e-01,  2.60296e-01,  4.18263e-01,  ...,  4.49687e-02, -6.45795e-01, -2.78874e-01],\n",
       "            [-3.46698e-01,  5.58551e-01, -6.41500e-01,  ..., -1.80720e-02, -3.69887e-01,  1.17386e-01]]],\n",
       " \n",
       " \n",
       "          [[[ 2.32449e-01,  9.03963e-02, -6.09993e-01,  ..., -4.84525e-02, -2.09474e-01,  4.43779e-01],\n",
       "            [ 4.39596e-01, -2.10692e-01, -7.57062e-01,  ..., -2.96901e-01, -2.40195e-01,  3.09827e-01],\n",
       "            [ 6.60291e-01,  3.86915e-01, -7.67390e-01,  ...,  5.78782e-01,  2.63735e-01,  7.41226e-01],\n",
       "            ...,\n",
       "            [-2.89311e-01,  2.63682e-01, -1.65590e-01,  ..., -1.74575e-01, -1.12079e-01,  4.20626e-02],\n",
       "            [-1.35122e-01,  8.39810e-01, -4.06812e-01,  ..., -8.08237e-02,  6.20164e-02,  1.72219e-01],\n",
       "            [ 3.92780e-01,  1.95468e-01, -8.30485e-02,  ..., -7.21591e-02,  2.06765e-01,  1.76370e-01]],\n",
       " \n",
       "           [[-1.20431e-01,  1.78364e-01,  3.39839e-02,  ..., -2.28642e-01, -4.20254e-01,  3.31612e-01],\n",
       "            [ 8.17055e-01,  4.47235e-02, -4.53060e-01,  ...,  3.85793e-02,  1.58508e-01, -1.87554e-01],\n",
       "            [ 6.98183e-01,  2.45109e-01, -6.96011e-01,  ..., -2.51167e-01,  1.92946e-01,  9.37519e-02],\n",
       "            ...,\n",
       "            [-1.03585e+00,  1.64592e+00,  1.10008e-01,  ...,  1.45581e-03, -9.18536e-01, -5.41023e-01],\n",
       "            [ 1.73241e-01, -5.36508e-01, -3.42713e-01,  ..., -1.29758e-01, -4.55267e-01,  1.49845e-01],\n",
       "            [-5.17586e-01,  2.97352e-01, -7.25934e-02,  ..., -3.45577e-02, -5.49860e-02,  1.18506e-01]],\n",
       " \n",
       "           [[ 3.59588e-01,  9.10211e-02,  1.13852e-01,  ...,  2.14925e-01, -1.65129e-01,  1.21832e-01],\n",
       "            [ 1.86756e-01, -2.58548e-01,  2.49465e-01,  ..., -2.87500e-01, -1.08335e-01,  5.86448e-01],\n",
       "            [-3.71435e-02,  2.93369e-02, -8.64810e-01,  ..., -2.89749e-01,  5.66879e-01, -4.64154e-01],\n",
       "            ...,\n",
       "            [ 3.02167e-01,  2.37456e-01, -4.71014e-01,  ..., -1.02484e-01,  9.82196e-03,  7.85210e-02],\n",
       "            [ 3.65327e-01,  2.53936e-01,  3.07831e-01,  ..., -7.80615e-02,  5.56150e-01, -4.97389e-01],\n",
       "            [ 6.04848e-03, -2.95251e-01, -1.91530e-01,  ...,  2.21303e-01, -3.18488e-02,  3.18763e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 1.67196e-01,  3.22706e-01, -4.53316e-01,  ...,  9.97704e-02, -5.99691e-02,  3.06484e-01],\n",
       "            [-1.13133e+00, -3.81321e-01,  1.44428e-01,  ..., -3.84171e-01,  1.25039e-01,  8.19421e-01],\n",
       "            [-2.46024e-02, -2.17362e-01,  5.21291e-01,  ...,  2.83581e-01, -6.68488e-02,  2.31808e-01],\n",
       "            ...,\n",
       "            [ 1.09098e+00, -1.00032e+00, -2.16508e-02,  ...,  7.92059e-01,  1.77991e-01,  9.00552e-02],\n",
       "            [ 8.41339e-01,  4.91391e-01, -2.66237e-01,  ...,  5.39712e-01, -7.12125e-01, -2.85663e-01],\n",
       "            [-2.12786e-02, -2.97908e-01,  9.07124e-01,  ..., -2.88902e-01,  2.17911e-01, -4.65461e-01]],\n",
       " \n",
       "           [[-4.80465e-01,  3.53192e-01,  3.00103e-02,  ..., -7.09393e-01, -3.56914e-01,  2.74767e-01],\n",
       "            [-1.10166e+00,  1.24223e-01,  1.51298e-01,  ..., -2.88065e-01,  4.49878e-01,  3.77962e-01],\n",
       "            [-6.34797e-03, -3.21460e-01,  7.97481e-01,  ..., -9.67912e-01, -4.15311e-01,  3.32940e-01],\n",
       "            ...,\n",
       "            [-3.32765e-01,  2.92289e-01,  2.76310e-01,  ...,  3.16094e-01, -4.36646e-01,  1.43594e-01],\n",
       "            [-6.30454e-01,  1.44075e-01,  1.76796e-01,  ...,  6.16395e-01, -4.84417e-01,  6.47824e-02],\n",
       "            [-2.97500e-01, -1.53326e-01,  1.56550e-01,  ...,  3.31483e-01,  4.01107e-02, -4.74547e-01]],\n",
       " \n",
       "           [[ 2.52571e-01,  5.60353e-01, -2.74011e-01,  ...,  7.59460e-02, -1.07170e-01,  6.20876e-01],\n",
       "            [-9.03792e-02,  3.04841e-02,  1.17764e-01,  ...,  1.35183e-02,  3.81117e-01,  4.45871e-01],\n",
       "            [ 4.08959e-01, -6.33175e-01,  4.59607e-01,  ..., -1.82108e-01, -4.75530e-01,  1.59442e-01],\n",
       "            ...,\n",
       "            [-4.49127e-01, -6.46800e-01, -9.76752e-02,  ..., -3.04756e-01,  5.65432e-01,  5.91689e-01],\n",
       "            [ 5.66899e-02,  2.08055e-01,  1.61686e-01,  ...,  8.52716e-02, -1.19841e-01,  4.87536e-01],\n",
       "            [-3.28052e-01, -1.82908e-01, -5.19546e-02,  ..., -6.55698e-02, -2.23137e-01,  5.33266e-01]]],\n",
       " \n",
       " \n",
       "          [[[-1.07386e-01,  2.14640e-01,  4.81280e-01,  ...,  7.23640e-02, -3.82881e-01, -4.21529e-03],\n",
       "            [ 1.17790e-01, -1.15289e-01, -1.21750e-02,  ..., -8.52503e-02, -5.27795e-01, -1.74658e-03],\n",
       "            [ 1.49056e-01, -3.93033e-01,  2.84362e-01,  ..., -1.88375e-01, -2.13188e-01, -4.01094e-01],\n",
       "            ...,\n",
       "            [ 1.79595e-01, -6.61869e-01,  1.02159e+00,  ...,  1.75173e-01, -1.34678e-01,  3.42821e-01],\n",
       "            [-1.52949e-01, -5.97965e-01,  1.49687e-01,  ..., -2.91548e-01, -2.42870e-02,  1.12472e-01],\n",
       "            [ 2.25110e-01, -1.62213e-01,  6.41639e-01,  ...,  3.39275e-02, -7.56541e-01,  7.57769e-01]],\n",
       " \n",
       "           [[-2.35480e-01,  9.30793e-04,  3.93946e-01,  ..., -1.84439e-01,  3.23714e-01,  4.00163e-01],\n",
       "            [-4.57960e-01, -2.86314e-01,  5.73080e-01,  ..., -8.54606e-01,  1.82687e-01, -1.58365e-02],\n",
       "            [-3.79462e-01,  1.04658e+00,  4.14862e-01,  ...,  9.70830e-02, -2.67656e-02,  7.28606e-02],\n",
       "            ...,\n",
       "            [-1.21862e+00,  3.65351e-01,  6.46564e-01,  ..., -1.18961e-01, -7.48097e-01,  3.01283e-01],\n",
       "            [-6.81773e-01,  1.62927e-01, -1.24332e-01,  ..., -1.01170e+00,  6.19442e-02,  2.64433e-03],\n",
       "            [-3.16365e-01, -3.08143e-02,  5.81511e-01,  ...,  9.12839e-03, -1.09595e-01, -5.30774e-01]],\n",
       " \n",
       "           [[-1.41435e-01,  4.27256e-01,  8.95752e-01,  ..., -8.71693e-02, -2.66842e-01,  3.03590e-01],\n",
       "            [-2.58219e-01,  4.47779e-01, -1.80790e-01,  ..., -4.44971e-01,  2.33900e-01, -1.49161e-02],\n",
       "            [ 1.69970e-01, -9.18184e-01,  8.37491e-01,  ...,  1.96550e-01,  2.92780e-01,  1.11229e+00],\n",
       "            ...,\n",
       "            [-6.53145e-01, -8.61160e-01,  3.82196e-01,  ..., -9.00601e-01, -3.72838e-01,  9.62867e-01],\n",
       "            [ 5.15070e-01, -6.50833e-02,  1.82564e-01,  ..., -1.08592e+00, -6.45043e-01, -3.31968e-01],\n",
       "            [ 2.57032e-01, -7.55072e-02,  3.24827e-01,  ...,  1.74642e-02, -5.46723e-01,  4.42794e-01]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[ 5.61770e-01, -1.44326e-01,  5.55980e-01,  ..., -5.07927e-01,  2.25276e-02, -7.21924e-01],\n",
       "            [-2.71807e-02,  1.31103e+00,  2.81093e-01,  ..., -1.07603e+00,  2.41459e-01,  5.40666e-01],\n",
       "            [-5.42362e-01, -3.16456e-01,  8.68314e-01,  ..., -2.27272e-01,  4.71805e-01, -8.57078e-02],\n",
       "            ...,\n",
       "            [-8.48527e-01, -1.37357e-01,  5.65211e-01,  ..., -5.17693e-01, -6.70548e-03, -6.35562e-01],\n",
       "            [-3.51927e-01, -4.68427e-01, -1.71049e-01,  ..., -3.68925e-01, -4.81713e-01,  8.17441e-01],\n",
       "            [-3.20626e-01,  2.65065e-01,  4.41606e-02,  ..., -7.65912e-01,  4.50063e-03, -1.55978e-01]],\n",
       " \n",
       "           [[-8.62524e-01, -2.40245e-01,  2.47320e-01,  ...,  4.86687e-01, -2.12130e-02,  3.53699e-01],\n",
       "            [-3.54137e-01, -4.87420e-01,  6.17396e-01,  ...,  3.25939e-01, -5.03554e-01, -7.18407e-02],\n",
       "            [-3.92250e-01, -4.02847e-02,  6.65050e-01,  ...,  5.78167e-01, -2.28321e-01,  5.11103e-02],\n",
       "            ...,\n",
       "            [-9.78212e-01,  3.61301e-01,  2.63223e-01,  ..., -7.14827e-01, -1.09771e+00,  2.14353e-01],\n",
       "            [-6.23841e-02, -5.92300e-01,  4.18516e-01,  ..., -7.86063e-01, -1.85740e-01,  1.58736e-03],\n",
       "            [-2.78248e-01, -2.37026e-01,  7.88985e-01,  ..., -1.67380e-01, -1.18960e-01,  5.71788e-02]],\n",
       " \n",
       "           [[ 2.06372e-01,  8.62478e-02,  5.08614e-01,  ...,  6.38753e-02, -4.22750e-01, -3.33583e-01],\n",
       "            [-2.35244e-01, -1.99725e-01,  1.22886e+00,  ...,  4.06108e-01, -1.26093e-02, -1.85923e-01],\n",
       "            [ 2.01415e-01,  3.69142e-01,  1.25792e+00,  ..., -1.36247e-01, -4.51023e-01, -6.86061e-01],\n",
       "            ...,\n",
       "            [-4.68965e-01, -4.98346e-02,  2.22276e-01,  ..., -1.79522e-01,  2.85045e-01, -4.80732e-01],\n",
       "            [ 1.76039e-01, -6.10760e-01, -7.40062e-01,  ..., -9.49275e-01, -2.41142e-01, -4.03023e-01],\n",
       "            [-4.15873e-01, -1.58732e-01, -3.79030e-02,  ..., -7.17365e-02, -2.48612e-01, -5.30707e-01]]]]], grad_fn=<CloneBackward0>)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256, 256)\n",
    "runtime_depth = [3,2,2,1,5,5,5,3]\n",
    "\n",
    "forward_once(model, input, runtime_depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "y, dt = [], []  # outputs\n",
    "for i, m in enumerate(model):\n",
    "    if m.f != -1:  # if not from previous layer\n",
    "        x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "        \n",
    "    x = m(x)  # run\n",
    "    \n",
    "    y.append(x if m.i in save else None)  # save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELANBlock for Backbone\n",
    "class ELANBlock(nn.Module):\n",
    "    def __init__(self, c1, k, depth):\n",
    "        super(ELANBlock, self).__init__()\n",
    "        assert c1 % 2 == 0 and depth < 5\n",
    "        c_ = int(c1 / 2)\n",
    "        c2 = int(c1 / 2 * (depth+1))\n",
    "        self.depth = depth\n",
    "        # depth 1\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c1, c_, 1, 1)\n",
    "        # depth 2\n",
    "        self.cv3 = Conv(c_, c_, 3, 1)\n",
    "        self.cv4 = Conv(c_, c_, 3, 1)\n",
    "        # depth 3\n",
    "        self.cv5 = Conv(c_, c_, 3, 1)\n",
    "        self.cv6 = Conv(c_, c_, 3, 1)\n",
    "        # depth 4\n",
    "        self.cv7 = Conv(c_, c_, 3, 1)\n",
    "        self.cv8 = Conv(c_, c_, 3, 1)\n",
    "        \n",
    "        self.cat = Concat(dimension=1)\n",
    "        \n",
    "        self.blocks, self.act_idx = self.set_blocks(c1, k, s, depth)\n",
    "    \n",
    "    def set_blocks(self, c1, k, s, depth):\n",
    "        c_ = int(c1 / 2)\n",
    "        layers = []\n",
    "        # depth에 따라 from 이 결정됨.\n",
    "        # depth = 3\n",
    "        act_idx = [0, 1, 3, 5, 7][:depth] \n",
    "        f = [-1, -3, -5, -6]\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                # depth 1\n",
    "                m1, m2 = Conv(c1, c_, 1, 1), Conv(c1, c_, 1, 1)\n",
    "                m1.i, m1.f = i, 0\n",
    "                m2.i, m2.f = i+1, 0\n",
    "                layers.append(m1)\n",
    "                layers.append(m2)\n",
    "                # layers.append(Conv(c1, c_, 1, 1))\n",
    "                # layers.append(Conv(c1, c_, 1, 1))\n",
    "            else:\n",
    "                # another depth\n",
    "                m3, m4 = Conv(c_, c_, k, 1), Conv(c_, c_, k, 1)\n",
    "                m3.i, m3.f = 2*i, 2*i-1\n",
    "                m4.i, m4.f = 2*i+1, 2*i\n",
    "                layers.append(m3)\n",
    "                layers.append(m4)\n",
    "                # layers.append(Conv(c_, c_, k, 1))\n",
    "                # layers.append(Conv(c_, c_, k, 1))\n",
    "                m = nn.Sequential(\n",
    "                    Conv(c_, c_, k, 1),\n",
    "                    Conv(c_, c_, k, 1)\n",
    "                )\n",
    "                \n",
    "        \n",
    "        layers.append(Concat(1))\n",
    "        return nn.Sequential(*layers), act_idx\n",
    "    \n",
    "    # def forward(self, x):\n",
    "    #     x1 = self.cv1(x)\n",
    "    #     x2 = self.cv2(x)    \n",
    "    #     # depth 2\n",
    "    #     x3 = self.cv3(x2)\n",
    "    #     x4 = self.cv4(x3)\n",
    "    #     # depth 3\n",
    "    #     x5 = self.cv5(x4)\n",
    "    #     x6 = self.cv6(x5)\n",
    "        \n",
    "    #     x = self.depth\n",
    "    #     return torch.cat([x1, x2, x4, x6], dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        x1 = self.cv1(x)\n",
    "        outputs.append(x1)\n",
    "        x2 = self.cv2(x)    \n",
    "        outputs.append(x2)\n",
    "        # depth 2\n",
    "        x3 = self.cv3(x2)\n",
    "        outputs.append(x3)\n",
    "        x4 = self.cv4(x3)\n",
    "        outputs.append(x4)\n",
    "        # depth 3\n",
    "        x5 = self.cv5(x4)\n",
    "        outputs.append(x5)\n",
    "        x6 = self.cv6(x5)\n",
    "        outputs.append(x6)\n",
    "        # depth 4\n",
    "        x7 = self.cv7(x6)\n",
    "        outputs.append(x7)\n",
    "        x8 = self.cv8(x7)\n",
    "        outputs.append(x8)\n",
    "        \n",
    "        return torch.cat([outputs[i] for i in self.act_idx], dim=1) # 0, 1, 3, 5 \n",
    "        # return torch.cat([x1, x2, x4, x6], dim=1)\n",
    "    \n",
    "    def forward_blocks(self, x, depth=3):\n",
    "        self.saved = []\n",
    "        output = []\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if isinstance(block.f, int):\n",
    "                output.append(block(x))\n",
    "            \n",
    "        return self.cat(output[self.act_idx])            \n",
    "\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 128, 64, 64)\n",
    "block = ELANBlock(c1=128, k=3, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
